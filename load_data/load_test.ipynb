{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working Example of a Data Loading Notebook\n",
    "For many indicators, we will not be able to pull dynamic data from a data API. In these cases, we will need to manually load the data into the database. This notebook provides a working example of how to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Connecting to Live Databases\n",
    "\n",
    "We will need to be able to work with the live running instances of our databases.  Right now, we're using MongoDB to store our semistructured data. There are two flavors of live databases: (1) the databases  which require authentication to access.  We protect these databases so that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sys import path\n",
    "# path.append('../')\n",
    "\n",
    "from database_connector.SSPIDatabaseConnector import SSPIDatabaseConnector\n",
    "database = SSPIDatabaseConnector()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Import the Data\n",
    "\n",
    "Our goal with moving the SSPI Data Pipeline to a code-only framework is to guarantee the reproducibility of our results, and all of that starts with how we work with our raw data.  The **best practice** for working with raw data is to keep a completely unaltered version of what you've downloaded and to work directly from that.  Occasionally, we will run into situations where this will not be feasible, but in almost all cases we will be working from the originals. We will be saving all of our our raw data downloads in the SSPI Google Drive, which we can link to directly from here.  I'll be working on implementing a direct connection to our Google Drive through their API down the line, but that's not strictly necessary to get started.  For now, link to the raw file you've downloaded in your data loading notebook.\n",
    "\n",
    "For example, the data we're using for the EPI come from \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
